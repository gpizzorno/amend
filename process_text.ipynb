{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import regex as re # https://github.com/mrabarnett/mrab-regex\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "plt.style.use(['dark_background'])\n",
    "InteractiveShell.ast_node_interactivity = \"none\"\n",
    "pd.options.display.max_rows = 500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "# progress bar\n",
    "def p_bar(mx, desc):\n",
    "    global p\n",
    "    p = IntProgress(min=0, max=mx, description=desc)\n",
    "    return p\n",
    "\n",
    "\n",
    "def find_amendment_end(text, amendment_start):\n",
    "    end_quote = last_amendment_char.search(text)\n",
    "    end_eof = last_amendment_char_eof.search(text)\n",
    "    \n",
    "    if end_quote and end_eof:\n",
    "        return max([end_quote.end(), end_eof.end()])\n",
    "    elif end_quote:\n",
    "        return end_quote.end()\n",
    "    elif end_eof:\n",
    "        return end_eof.end()\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def extract_amendment(text, jr_string):\n",
    "    \n",
    "    if jr_string:\n",
    "        start_match = pre_para_jr.search(text)\n",
    "    else:\n",
    "        start_match = pre_para_const.search(text)\n",
    "    \n",
    "    if start_match:\n",
    "        start = start_match.end()\n",
    "        end = find_amendment_end(text, start)\n",
    "    \n",
    "        return text[start:end] if end else text[start:]\n",
    "           \n",
    "    return 'EXTRACTION FAILED'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "# production:\n",
    "#raw_text_path = 'data/raw_text/'\n",
    "#save_data_path = 'data/'\n",
    "#clean_text_path = 'data/clean_txt/'\n",
    "\n",
    "# testing:\n",
    "raw_text_path = 'test_data/sample/'\n",
    "save_data_path = 'test_data/'\n",
    "clean_text_path = 'test_data/clean_sample/'\n",
    "english_dict_path = 'data/nltk_english_words'  # path to dictionary of all English words\n",
    "\n",
    "# load English dictionary\n",
    "with open(english_dict_path, 'r') as file:\n",
    "    english_words = set(file.read().split('\\n'))\n",
    "\n",
    "# load document statistics\n",
    "with open(f'{save_data_path}text_file_statistics.csv', 'r') as file:\n",
    "    doc_data = list(csv.DictReader(file))\n",
    "    \n",
    "# filters \n",
    "ascii_chars = re.compile(\"\"\"[^!\"#$%&'()*+,-.0-9:; =\\?A-Z\\[\\]_`a-z\\t\\n]\"\"\")\n",
    "word_chars = re.compile(\"[^a-zA-Z0-9 -']\")\n",
    "\n",
    "# detectors\n",
    "pre_para_jr = re.compile('JOINT RESOLUTION{e<=3}[\\w ,\\n\\.\\d\\t\\(\\)-]+:\\n')  # preceeding paragraph - JOINT RESOLUTION \n",
    "pre_para_const = re.compile('[constiu]+(-\\n)?[onstiu]+ ?:\\n', re.IGNORECASE|re.BESTMATCH)  # preceeding paragraph - Constitution:\n",
    "last_amendment_char = re.compile('\\.\"?\\n', re.REVERSE)\n",
    "last_amendment_char_eof = re.compile('\\.\"?$', re.REVERSE|re.MULTILINE)\n",
    "amendment_dividers = re.compile('.{,2}article|sec.{,2}\\n', re.IGNORECASE)  # text separating sections\n",
    "\n",
    "# cleaning\n",
    "replaces = {\n",
    "    'empty_lines': (\n",
    "        re.compile('^\\n', re.MULTILINE), \n",
    "        ''\n",
    "    ),\n",
    "    'empty_numbered_lines': (\n",
    "        re.compile('^[.*]?[gIfloOzZBJ\\d]{1,2}[ .]{0,2}$', re.MULTILINE),\n",
    "        ''\n",
    "    ),\n",
    "    'numbered_lines': (\n",
    "        re.compile('^[.*]?[gIfloOzZBJ\\d]{1,2}\\.?(?: |\\t)(?=[\\w ,\\.\\d\\t\\(\\)-:;\\'\\\"\\”]+$)', re.MULTILINE),\n",
    "        ''\n",
    "    ),\n",
    "    'quotation_marks': (\n",
    "        re.compile(\"\"\"''\\.?|«|»|“|”|„|‟|❝|❞|〝|〞|〟|＂\"\"\"),\n",
    "        '\"'\n",
    "    ),\n",
    "    'tabs_as_space': (\n",
    "        re.compile('\\t'),\n",
    "        ' '\n",
    "    ),\n",
    "    'whitespace_at_linestart': (\n",
    "        re.compile('^\\s+', re.MULTILINE),\n",
    "        ''\n",
    "    ),\n",
    "    'whitespace_at_lineend': (\n",
    "        re.compile('\\s+$', re.MULTILINE),\n",
    "        ''\n",
    "    ),\n",
    "    'hyphenated_words': (\n",
    "        re.compile('-\\n'),\n",
    "        ''\n",
    "    ),\n",
    "    'multiple_spaces': (\n",
    "        re.compile('[ ]+'),\n",
    "        ' '\n",
    "    ),\n",
    "    'carriage_returns': (\n",
    "        re.compile('(?<!\\.)\\n'),\n",
    "        ' '\n",
    "    ),\n",
    "    'spaces_before_punctuation': (\n",
    "        re.compile('\\s+(?=[.;,:])'),\n",
    "        ''\n",
    "    ),\n",
    "    'repeated_punctuation': (\n",
    "        re.compile('(?<=(?P<punct>,|\\.|;|:))\\g<punct>+'),\n",
    "        ''\n",
    "    ),\n",
    "    'orphaned_quotation_marks': (\n",
    "        re.compile('(?<!\")((?:.|\\n)+)\"'),\n",
    "        r'\\1'\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "# sets\n",
    "pre_process = ['empty_lines', 'empty_numbered_lines', 'numbered_lines', 'quotation_marks', 'empty_lines']\n",
    "clean_amendment = ['tabs_as_space', 'multiple_spaces', 'whitespace_at_linestart', 'whitespace_at_lineend', \n",
    "                   'hyphenated_words', 'carriage_returns', 'spaces_before_punctuation', 'repeated_punctuation',\n",
    "                   'orphaned_quotation_marks']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca652b49682846a2805f95c008ec361d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Processing', max=24)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(p_bar(len(doc_data), 'Processing')) # show the progress bar\n",
    "\n",
    "for i, doc in enumerate(doc_data):\n",
    "    \n",
    "    if float(doc['english_words']) > 50:  # threshold for non-rubbish text\n",
    "        filename = doc['filename']\n",
    "        \n",
    "        with open(f'{raw_text_path}{filename}', 'r') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # general cleanup\n",
    "        text = ascii_chars.sub('', text) # remove non-ascii characters\n",
    "        \n",
    "        for task in pre_process:\n",
    "            pattern = replaces[task][0]\n",
    "            fix = replaces[task][1]\n",
    "            text = pattern.sub(fix, text)\n",
    "        \n",
    "        # extract amendment text\n",
    "        clean_text = extract_amendment(text, bool(int(doc['jr_string'])))\n",
    "        \n",
    "        # clean amendment text\n",
    "        for task in clean_amendment:\n",
    "            pattern = replaces[task][0]\n",
    "            fix = replaces[task][1]\n",
    "            clean_text = pattern.sub(fix, clean_text)\n",
    "        \n",
    "        # save results\n",
    "        with open(f'{clean_text_path}{filename}', 'w') as file:\n",
    "            file.write(clean_text)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        p.value += 100  #update progress bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "That for the purpose Of choosing representa-\n",
    "That, for the purpose of choosing Representatives in the.\n",
    "to all intents and purposes,:;. as part of the said Constitution :\n",
    "That. 1‘or the purpose of choosing Representatives in the\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "pat = replaces['repeated_punctuation'][0]\n",
    "\n",
    "print(pat.search(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ascii_chars.sub('', text)\n",
    "\n",
    "for pattern, fix in general:\n",
    "    text = pattern.sub(fix, text)\n",
    "\n",
    "print(text)\n",
    "print(pre_para.search(text))\n",
    "print(last_amendment_char.search(text))\n",
    "print(last_amendment_char_eof.search(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = extract_amendment(text)\n",
    "print(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pre_para.search(text)\n",
    "\n",
    "if result is not None:\n",
    "    print(result)\n",
    "    print(result.start())\n",
    "    print(result.end())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(last_amendment_char.search(text))\n",
    "print(last_amendment_char.search(text).end())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text[757:1470])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
